# Contributions ```C```:
A NAS-like unified framework that can automate the search of ViT backbone design and scaling efficiently.

# Takeaways

---

**Quotes**

ViTs can tolerate coarse tokenization in early training stages.

Attention maps of ViTs gradually become similar in deeper layers, leading to identical feature maps and saturated performance.
NTK condition number
<img src="https://render.githubusercontent.com/render/math?math={\kappa_{\Theta}=\frac{\lambda_{max}}{\lambda_{min}}}">
to indicate the trainability of ViTs.

---

